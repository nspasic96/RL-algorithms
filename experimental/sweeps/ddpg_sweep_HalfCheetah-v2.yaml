name: DDPG-MountainCarContinuous-v0
program: ./ddpg_paper.py
method: bayes
metric:
  name: episode_reward_latest_mean
  goal: maxmimize
parameters:
  gym-id:
    value: "MountainCarContinuous-v0"
  seed:
    values: [1,2,5,10,1000]
  total_train_steps:
    value: 200000
  rho:
    values: [0.001, 0.005]
  learning_rate_q:
    values: [1e-3, 7e-4, 1e-4]
  hidden_layers_q:
    value: 50
  learning_rate_policy:
    values: [1e-3, 7e-4, 1e-4]
  hidden_layers_policy:
    value: 50
  buffer_size:
    values: [100000, 150000]
  batch_size:
    values: [64, 256]
  update_after:
    values: [5000, 20000]
  update_freq: 
    values: [50, 200]
  start_steps:
    value: 10000
  eps_start:
    min: 0.5
    max: 1
  eps_end:
    min: 0.01
    max: 0.05
  steps_to_decrease:
    value: 130000
  max_episode_len:
    value: 1000
  wandb_log:
    value: False
  plot_histograms:
    value: True
  play_every_nth_epoch:
    value: 10