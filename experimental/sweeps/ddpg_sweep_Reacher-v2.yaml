name: DDPG-Reacher-v2
program: ./ddpg_paper.py
method: bayes
metric:
  name: episode_reward_latest_mean
  goal: maxmimize
parameters:
  gym-id:
    value: "Reacher-v2"
  seed:
    values: [1,2,None]
  total_train_steps:
    value: 800000
  rho:
    values: [0.001, 0.005]
  learning_rate_q:
    values: [1e-3, 7e-4, 1e-4]
  learning_rate_policy:
    values: [1e-3, 7e-4, 1e-4]
  buffer_size:
    value: 400000
  batch_size:
    values: [32, 64]
  update_after:
    value: 1000
  update_freq: 
    values: [20, 50]
  start_steps:
    value: 3000
  eps_start:
    min: 0.2
    max: 0.3
  eps_end:
    min: 0.01
    max: 0.05
  steps_to_decrease:
    values: [100000, 400000]
  max_episode_len:
    value: 50
  wandb_log:
    value: False
  plot_histograms:
    value: True
  play_every_nth_epoch:
    value: 100000